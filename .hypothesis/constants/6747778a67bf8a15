# file: /Users/les/Projects/oneiric/oneiric/adapters/embedding/onnx.py
# hypothesis_version: 6.151.4

[-1000000000.0, 1e-12, 1e-09, 384, 450, 512, 768, '1.0.0', 'AI Platform', 'CPUExecutionProvider', 'ONNX_', 'ORT_DISABLE_ALL', 'ORT_ENABLE_ALL', 'ORT_ENABLE_BASIC', 'ORT_ENABLE_EXTENDED', 'adapter', 'async_operations', 'attention_mask', 'batch_embedding', 'batching', 'caching', 'chunk_overlap', 'chunk_size', 'cosine', 'description', 'dimensions', 'document_id', 'dot', 'edge_optimized', 'embedding', 'enable_cpu_mem_arena', 'enable_mem_pattern', 'encode', 'error', 'euclidean', 'graph_optimization', 'health check test', 'initialization test', 'input_ids', 'input_names', 'inter_op_threads', 'intra_op_threads', 'is_chunk', 'loading-onnx-model', 'local', 'main', 'manhattan', 'max_seq_length', 'metrics', 'model_path', 'name', 'np', 'on_device', 'onnx', 'onnx-batch-completed', 'onnx-batch-failed', 'onnx-model-loaded', 'onnx-test-success', 'onnxruntime', 'optimized', 'output_names', 'performance', 'pooling_strategies', 'pooling_strategy', 'profiling_data', 'profiling_enabled', 'provider', 'providers', 'requires_api_key', 'session_options', 'text_preprocessing', 'token_type_ids', 'tokenizer', 'transformers', 'type', 'vector_normalization']